{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP projection (9, 64, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine if the synthetic is privacy preserving both in pixel space and in feature space. In this notebook we create the feature extractor (a UMAP transform reducing to 32 principal components) and apply it to the relevant images in order to obtain their corresponding features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import h5py\n",
    "import pickle\n",
    "import umap\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = np.load('./privacy_saves/candidate.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('./privacy_saves/synth_set.h5', 'r')\n",
    "synth_set = h5f['images'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('./privacy_saves/test_set.h5', 'r')\n",
    "test_set = h5f['images'][-1000:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train UMAP\n",
    "Optionnal can be skipped to load a pre-trained umap. This step usually takes around 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('./privacy_saves/test_set.h5', 'r')\n",
    "temp_test = h5f['images'][333:1333]\n",
    "temp_test = np.array(test_set.reshape([len(temp_test), 9*64*64]))\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('./privacy_saves/val_set.h5', 'r')\n",
    "temp_val = h5f['images'][333:1833]\n",
    "temp_val = np.array(test_set.reshape([len(temp_val), 9*64*64]))\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('./privacy_saves/val_set.h5', 'r')\n",
    "temp_train = h5f['images'][1000:3500]\n",
    "temp_train = np.array(test_set.reshape([len(temp_train), 9*64*64]))\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_dataset = np.concatenate((temp_test, temp_val, temp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training UMAP\n",
    "# Umap projects into \n",
    "trans = umap.UMAP(n_neighbors=20, random_state=10, min_dist = 0.0,\n",
    "                  n_components=32).fit(umap_dataset.reshape([5000, 9*64*64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained UMAP object using pickle\n",
    "f_name = './privacy_saves/umap_privacy_5000.sav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'umap.umap_.UMAP'>\n"
     ]
    }
   ],
   "source": [
    "f_name = './privacy_saves/umap_privacy_5000.sav'\n",
    "loaded_model = pickle.load((open(f_name, 'rb')))\n",
    "print(type(loaded_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform with UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Test with UMAP\n",
    "Used as a reference features in embedding space (since test samples can help define the notion of outliers). Only used in supplemental figure in notebook 4_plot_membership_attacks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_umap = loaded_model.transform(test_set.reshape([len(test_set), 9*64*64]))\n",
    "np.save('./privacy_saves/u_test.npy', test_umap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform synth with UMAP\n",
    "Synthetic images to feature space. Used in all privacy attacks that happend in feature space. <br/>\n",
    "Please note that this step takes a very long time because the synthetic dataset is very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_umap = loaded_model.transform(synth_set.reshape([len(synth_set), 9*64*64]))\n",
    "np.save('./privacy_saves/u_synth.npy', synth_umap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform candidate with UMAP\n",
    "Candidates images projected to feature space. Used in all privacy attacks that happend in feature space. If a candidate that originated from training shares the same features as one or many synthetic samples and can easily be identified as such, then it can be considered as privacy threatening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_umap = loaded_model.transform(candidate.reshape([len(candidate), 9*64*64]))\n",
    "np.save('./privacy_saves/u_candidate.npy', candidate_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fda-env torchvision",
   "language": "python",
   "name": "fda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
